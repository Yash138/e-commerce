{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utility import MongoDBHandler\n",
    "import pandas as pd\n",
    "from pymongo import UpdateOne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_suffixes(df, *args):\n",
    "    for i in args:\n",
    "        df = df.rename(columns={col: col.replace(i,'') for col in df.columns})\n",
    "    return df\n",
    "\n",
    "def add_suffixes(df, suffix):\n",
    "    return df.rename(columns={col: col+suffix for col in df.columns})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_handler = MongoDBHandler('mongodb://localhost:27017', 'ecommerce')\n",
    "mongo_handler.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product = pd.DataFrame(list(mongo_handler.find('stg_amz__product_details', {})))\n",
    "df_bs = pd.DataFrame(list(mongo_handler.find('trf_amz__best_sellers', {'isLatest':True})))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>B0BK1457X3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>B07XTJDJHN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B07PK41FL4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>B0C7BM18PB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>B01GRJGM0Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>B08WPWTZN4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4580</th>\n",
       "      <td>B0D2V7MY5Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4582</th>\n",
       "      <td>B07RDX8MLH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4650</th>\n",
       "      <td>B0CXXLRQRW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4652</th>\n",
       "      <td>B0CNRWFFJQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1974 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            asin\n",
       "0     B0BK1457X3\n",
       "2     B07XTJDJHN\n",
       "4     B07PK41FL4\n",
       "6     B0C7BM18PB\n",
       "8     B01GRJGM0Y\n",
       "...          ...\n",
       "4578  B08WPWTZN4\n",
       "4580  B0D2V7MY5Y\n",
       "4582  B07RDX8MLH\n",
       "4650  B0CXXLRQRW\n",
       "4652  B0CNRWFFJQ\n",
       "\n",
       "[1974 rows x 1 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(df_bs, df_product,on='asin', how='inner')[['asin']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>isLatest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [_id, isLatest]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trf = pd.DataFrame(list(mongo_handler.find('trf_amz__best_sellers', {'isLatest': True})))\n",
    "df_trf['d_rank'] = df_trf.groupby(['category','subCategory','rank'])['loadTimestamp'].rank(method='dense', ascending=True)\n",
    "df_upsert = df_trf[df_trf['d_rank']>1][['_id', 'isLatest']].assign(isLatest=False)\n",
    "df_upsert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not df_upsert.empty:\n",
    "    mongo_handler.bulk_upsert(\n",
    "        'trf_amz__best_sellers', \n",
    "        df_upsert, \n",
    "        filter_cols=['_id'],\n",
    "        upsert=True\n",
    "    )\n",
    "else:\n",
    "    print(\"NO DATA TO UPSERT\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from scrapy.utils.project import get_project_settings\n",
    "from psycopg2.extras import RealDictCursor, DictCursor, execute_values\n",
    "\n",
    "class PostgresDBHandler:\n",
    "    def __init__(self, host, database, user, password, port=5432):\n",
    "        \"\"\"Initialize connection parameters.\"\"\"\n",
    "        self.host = host\n",
    "        self.database = database\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.port = port\n",
    "        self.connection = None\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"Establish a connection to the PostgreSQL database.\"\"\"\n",
    "        try:\n",
    "            self.connection = psycopg2.connect(\n",
    "                host=self.host,\n",
    "                database=self.database,\n",
    "                user=self.user,\n",
    "                password=self.password,\n",
    "                port=self.port\n",
    "            )\n",
    "        except psycopg2.Error as e:\n",
    "            print(f\"Error connecting to PostgreSQL database: {e}\")\n",
    "            raise\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Close the database connection.\"\"\"\n",
    "        if self.connection:\n",
    "            self.connection.close()\n",
    "\n",
    "    def insert(self, table, data):\n",
    "        \"\"\"\n",
    "        Insert a record into the specified table.\n",
    "        \n",
    "        Args:\n",
    "            table (str): Name of the table.\n",
    "            data (dict): Dictionary of column-value pairs to insert.\n",
    "        \"\"\"\n",
    "        columns = ', '.join(data.keys())\n",
    "        values = ', '.join(['%s'] * len(data))\n",
    "        query = f\"INSERT INTO {table} ({columns}) VALUES ({values}) RETURNING id;\"\n",
    "        \n",
    "        try:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(query, tuple(data.values()))\n",
    "                self.connection.commit()\n",
    "                return cursor.fetchone()[0]\n",
    "        except psycopg2.Error as e:\n",
    "            self.connection.rollback()\n",
    "            print(f\"Error inserting into {table}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def read(self, table, columns='*', conditions=None):\n",
    "        \"\"\"\n",
    "        Read records from the specified table.\n",
    "        \n",
    "        Args:\n",
    "            table (str): Name of the table.\n",
    "            columns (str or list): Columns to retrieve (default is '*').\n",
    "            conditions (str): WHERE clause conditions (optional).\n",
    "        \n",
    "        Returns:\n",
    "            list[dict]: List of retrieved records as dictionaries.\n",
    "        \"\"\"\n",
    "        if isinstance(columns, list):\n",
    "            columns = ', '.join(columns)\n",
    "        query = f\"SELECT {columns} FROM {table}\"\n",
    "        if conditions:\n",
    "            query += f\" WHERE {conditions}\"\n",
    "        \n",
    "        try:\n",
    "            with self.connection.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "                cursor.execute(query)\n",
    "                return cursor.fetchall()\n",
    "        except psycopg2.Error as e:\n",
    "            print(f\"Error reading from {table}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def update(self, table, data, conditions):\n",
    "        \"\"\"\n",
    "        Update records in the specified table.\n",
    "        \n",
    "        Args:\n",
    "            table (str): Name of the table.\n",
    "            data (dict): Dictionary of column-value pairs to update.\n",
    "            conditions (str): WHERE clause conditions.\n",
    "        \"\"\"\n",
    "        set_clause = ', '.join([f\"{col} = %s\" for col in data.keys()])\n",
    "        query = f\"UPDATE {table} SET {set_clause} WHERE {conditions}\"\n",
    "        \n",
    "        try:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(query, tuple(data.values()))\n",
    "                self.connection.commit()\n",
    "                return cursor.rowcount  # Number of rows updated\n",
    "        except psycopg2.Error as e:\n",
    "            self.connection.rollback()\n",
    "            print(f\"Error updating {table}: {e}\")\n",
    "            raise\n",
    "\n",
    "    def bulk_upsert(self, table, data, conflict_columns, update_columns):\n",
    "        \"\"\"\n",
    "        Perform a bulk upsert operation.\n",
    "\n",
    "        Args:\n",
    "            table (str): Name of the table.\n",
    "            data (list[dict]): List of dictionaries, where keys are column names, and values are the row data.\n",
    "            conflict_columns (list[str]): List of columns to check for conflicts (e.g., primary or unique keys).\n",
    "            update_columns (list[str]): List of columns to update on conflict.\n",
    "        \"\"\"\n",
    "        # Ensure data is provided\n",
    "        if not data:\n",
    "            raise ValueError(\"No data provided for upsert.\")\n",
    "\n",
    "        # Generate the SQL parts dynamically\n",
    "        columns = data[0].keys()  # Assume all rows have the same keys\n",
    "        column_list = \", \".join(columns)\n",
    "        value_placeholders = \", \".join([f\"%({col})s\" for col in columns])\n",
    "\n",
    "        conflict_clause = \", \".join(conflict_columns)\n",
    "        update_clause = \", \".join([f\"{col} = EXCLUDED.{col}\" for col in update_columns])\n",
    "\n",
    "        query = f\"\"\"\n",
    "            INSERT INTO {table} ({column_list})\n",
    "            VALUES ({value_placeholders})\n",
    "            ON CONFLICT ({conflict_clause})\n",
    "            DO UPDATE SET\n",
    "            {update_clause};\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                # Use execute_values for efficiency\n",
    "                execute_values(cursor, query, data)\n",
    "                self.connection.commit()\n",
    "                print(f\"Bulk upsert completed for {len(data)} rows.\")\n",
    "        except psycopg2.Error as e:\n",
    "            self.connection.rollback()\n",
    "            print(f\"Error during bulk upsert: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def execute_stored_procedure(self, procedure_name):\n",
    "        \"\"\"\n",
    "        Execute a stored procedure in PostgreSQL.\n",
    "\n",
    "        Args:\n",
    "            procedure_name (str): The name of the stored procedure, including the schema (e.g., 'processed.sp_update_master_tables').\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                # Execute the stored procedure\n",
    "                cursor.execute(f\"CALL {procedure_name}();\")\n",
    "                self.connection.commit()\n",
    "                print(f\"Stored procedure {procedure_name} executed successfully.\")\n",
    "        except psycopg2.Error as e:\n",
    "            self.connection.rollback()\n",
    "            print(f\"Error executing stored procedure {procedure_name}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    def execute(self, query, type=None):\n",
    "        \"\"\"\n",
    "        Execute a query in PostgreSQL.\n",
    "\n",
    "        Args:\n",
    "            query (str): The whole sql query to be executed (e.g. select * from processed.amz__product_category)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with self.connection.cursor(cursor_factory=RealDictCursor) as cursor:\n",
    "                # Execute the stored procedure\n",
    "                cursor.execute(query)\n",
    "                self.connection.commit()\n",
    "                print(f\"Query executed successfully.\")\n",
    "                if type is None :\n",
    "                    return cursor.fetchall()\n",
    "        except psycopg2.Error as e:\n",
    "            self.connection.rollback()\n",
    "            print(f\"Error executing query {query}: {e}\")\n",
    "            raise\n",
    "    \n",
    "    \n",
    "    def delete(self, table, conditions):\n",
    "        \"\"\"\n",
    "        Delete records from the specified table.\n",
    "        \n",
    "        Args:\n",
    "            table (str): Name of the table.\n",
    "            conditions (str): WHERE clause conditions.\n",
    "        \"\"\"\n",
    "        query = f\"DELETE FROM {table} WHERE {conditions}\"\n",
    "        \n",
    "        try:\n",
    "            with self.connection.cursor() as cursor:\n",
    "                cursor.execute(query)\n",
    "                self.connection.commit()\n",
    "                return cursor.rowcount  # Number of rows deleted\n",
    "        except psycopg2.Error as e:\n",
    "            self.connection.rollback()\n",
    "            print(f\"Error deleting from {table}: {e}\")\n",
    "            raise\n",
    "\n",
    "\n",
    "\n",
    "def getCategoryUrls(db='mongo'):\n",
    "    if db == 'mongo':\n",
    "        mongo_handler = MongoDBHandler(\n",
    "            settings.get('MONGO_URI'),\n",
    "            settings.get('MONGO_DATABASE'))\n",
    "        results_category = mongo_handler.find(\n",
    "            \"amz__product_category\", \n",
    "            {'IsActive':True},\n",
    "            {'Category':1, 'SubCategory':{'$literal':''}, 'Url':1, '_id':0}\n",
    "        )\n",
    "\n",
    "        results_subCategory = mongo_handler.find(\n",
    "            \"amz__product_subcategory\", \n",
    "            {'IsActive':True},\n",
    "            {'Category':1, 'SubCategory':1, 'Url':1, '_id':0}\n",
    "        )\n",
    "        # print(list(results_category),list(results_subCategory))\n",
    "        results = list(results_category)+list(results_subCategory)\n",
    "        return results if results else []\n",
    "    elif db == 'postgres':\n",
    "        settings = get_project_settings()\n",
    "        postgres_handler = PostgresDBHandler(\n",
    "                settings.get('POSTGRES_HOST'),\n",
    "                settings.get('POSTGRES_DATABASE'),\n",
    "                settings.get('POSTGRES_USERNAME'),\n",
    "                settings.get('POSTGRES_PASSWORD'),\n",
    "                settings.get('POSTGRES_PORT'),\n",
    "            )\n",
    "        postgres_handler.connect()\n",
    "        if settings.get('LOAD_TYPE') == 'INCREMENTAL':\n",
    "            return postgres_handler.execute(\n",
    "                \"\"\"\n",
    "                SELECT category, '' as sub_category, url FROM processed.amz__product_category \n",
    "                WHERE is_active = true AND cast(last_refreshed_timestamp as date) < CURRENT_DATE\n",
    "                UNION\n",
    "                SELECT category, sub_category, url FROM processed.amz__product_subcategory \n",
    "                WHERE is_active = true AND cast(last_refreshed_timestamp as date) < CURRENT_DATE\n",
    "                \"\"\"\n",
    "            )\n",
    "        elif settings.get('LOAD_TYPE') == 'FULLREFRESH':\n",
    "            return postgres_handler.execute(\n",
    "                \"\"\"\n",
    "                select category, '' as sub_category, url from processed.amz__product_category WHERE is_active = true\n",
    "                union \n",
    "                select category, sub_category, url from processed.amz__product_subcategory WHERE is_active = true\n",
    "                \"\"\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully.\n",
      "['https://www.amazon.in/gp/bestsellers/luggage', 'https://www.amazon.in/gp/bestsellers/apparel', 'https://www.amazon.in/gp/bestsellers/industrial/7124091031', 'https://www.amazon.in/gp/bestsellers/kitchen', 'https://www.amazon.in/gp/bestsellers/shoes', 'https://www.amazon.in/gp/bestsellers/industrial/10572875031', 'https://www.amazon.in/gp/bestsellers/home-improvement/10615970031', 'https://www.amazon.in/gp/bestsellers/shoes/1983338031', 'https://www.amazon.in/gp/bestsellers/home-improvement/4286644031', 'https://www.amazon.in/gp/bestsellers/electronics', 'https://www.amazon.in/gp/bestsellers/home-improvement/10615921031', 'https://www.amazon.in/gp/bestsellers/home-improvement/29594128031', 'https://www.amazon.in/gp/bestsellers/automotive/5257478031', 'https://www.amazon.in/gp/bestsellers/hpc', 'https://www.amazon.in/gp/bestsellers/home-improvement/4286642031', 'https://www.amazon.in/gp/bestsellers/beauty', 'https://www.amazon.in/gp/bestsellers/industrial/7355311031', 'https://www.amazon.in/gp/bestsellers/home-improvement/5745030031', 'https://www.amazon.in/gp/bestsellers/watches', 'https://www.amazon.in/gp/bestsellers/kitchen/1380441031', 'https://www.amazon.in/gp/bestsellers/home-improvement/10616369031', 'https://www.amazon.in/gp/bestsellers/kitchen/1380510031', 'https://www.amazon.in/gp/bestsellers/computers', 'https://www.amazon.in/gp/bestsellers/industrial/7110888031', 'https://www.amazon.in/gp/bestsellers/home-improvement/10448916031', 'https://www.amazon.in/gp/bestsellers/jewelry', 'https://www.amazon.in/gp/bestsellers/automotive/5257472031', 'https://www.amazon.in/gp/bestsellers/industrial/22955924031', 'https://www.amazon.in/gp/bestsellers/home-improvement/4286645031', 'https://www.amazon.in/gp/bestsellers/kitchen/4286640031', 'https://www.amazon.in/gp/bestsellers/home-improvement/4286643031', 'https://www.amazon.in/gp/bestsellers/home-improvement/2083408031', 'https://www.amazon.in/gp/bestsellers/garden', 'https://www.amazon.in/gp/bestsellers/office', 'https://www.amazon.in/gp/bestsellers/home-improvement/4286641031', 'https://www.amazon.in/gp/bestsellers/industrial', 'https://www.amazon.in/gp/bestsellers/home-improvement', 'https://www.amazon.in/gp/bestsellers/grocery', 'https://www.amazon.in/gp/bestsellers/automotive']\n"
     ]
    }
   ],
   "source": [
    "print([i['url'] for i in getCategoryUrls(db='postgres')])\n",
    "\n",
    "# settings = get_project_settings()\n",
    "# postgres_handler = PostgresDBHandler(\n",
    "#         settings.get('POSTGRES_HOST'),\n",
    "#         settings.get('POSTGRES_DATABASE'),\n",
    "#         settings.get('POSTGRES_USERNAME'),\n",
    "#         settings.get('POSTGRES_PASSWORD'),\n",
    "#         settings.get('POSTGRES_PORT'),\n",
    "#     )\n",
    "# postgres_handler.connect()\n",
    "\n",
    "# postgres_handler.execute('CALL processed.sp_process_best_seller();')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getUrlToScrap(db:'mongo | postgres'='mongo'):\n",
    "    settings = get_project_settings()\n",
    "    if db == 'mongo':\n",
    "        mongo_handler = MongoDBHandler(\n",
    "            settings.get('MONGO_URI'),\n",
    "            settings.get('MONGO_DATABASE'))\n",
    "        urls = mongo_handler.find(\n",
    "            \"trf_amz__best_sellers\", \n",
    "            {'isLatest':True},\n",
    "            {'productUrl':1, '_id':0}\n",
    "        )\n",
    "        return list(urls)\n",
    "    elif db == 'postgres':\n",
    "        postgres_handler = PostgresDBHandler(\n",
    "                settings.get('POSTGRES_HOST'),\n",
    "                settings.get('POSTGRES_DATABASE'),\n",
    "                settings.get('POSTGRES_USERNAME'),\n",
    "                settings.get('POSTGRES_PASSWORD'),\n",
    "                settings.get('POSTGRES_PORT'),\n",
    "            )\n",
    "        postgres_handler.connect()\n",
    "        return postgres_handler.execute(\n",
    "            \"\"\"\n",
    "                select distinct product_url from processed.amz__best_sellers where asin not in (select distinct asin from staging.stg_amz__product_details)\n",
    "            \"\"\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'.'.isdigit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_number(num):\n",
    "    return ''.join([i for i in num if i.isdigit() or i=='.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1297'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_number('1,297 ratings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-09-25 00:00:00\n"
     ]
    }
   ],
   "source": [
    "date_string = \" 25 September 2023 \"\n",
    "date_object = dt.strptime(date_string.strip(), \"%d %B %Y\")\n",
    "print(date_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_numeric_part(value):\n",
    "    if isinstance(value, str):\n",
    "        # extract the numeric part\n",
    "        x = [i for i in value.split(' ') if re.search(r'\\d', i)]\n",
    "        if len(x) > 1:\n",
    "            raise Exception(f\"Expected One Numeric Part, got {len(x)}:{x}\")\n",
    "        # remove any special character exclude: decimal and alphanumeric letters\n",
    "        if x:\n",
    "            x = re.sub(r'[^a-zA-Z0-9\\s\\.]', '', x[0]).lower()\n",
    "            if x[-1] == 'k':\n",
    "                x = float(x.replace('k',''))*1000\n",
    "            elif x[-1] == 'l':\n",
    "                x = float(x.replace('l',''))*1_000_000\n",
    "            else:\n",
    "                x = float(x)\n",
    "            return x\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "extract_numeric_part('')\n",
    "# value = ''\n",
    "# if [i for i in value.split(' ') if re.search(r'\\d', i)]:\n",
    "#     print(True)\n",
    "# else:\n",
    "#     print(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example Usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Connection parameters\n",
    "    db_config = {\n",
    "        \"host\": \"localhost\",\n",
    "        \"database\": \"your_database\",\n",
    "        \"user\": \"your_user\",\n",
    "        \"password\": \"your_password\",\n",
    "        \"port\": 5432\n",
    "    }\n",
    "\n",
    "    # Initialize the CRUD class\n",
    "    db = PostgreSQLCRUD(**db_config)\n",
    "\n",
    "    # Connect to the database\n",
    "    db.connect()\n",
    "\n",
    "    # Example CRUD operations\n",
    "    try:\n",
    "        # CREATE\n",
    "        data_to_insert = {\"column1\": \"value1\", \"column2\": \"value2\"}\n",
    "        new_id = db.create(\"your_table\", data_to_insert)\n",
    "        print(f\"Inserted record with ID: {new_id}\")\n",
    "\n",
    "        # READ\n",
    "        records = db.read(\"your_table\", columns=[\"column1\", \"column2\"], conditions=\"column1 = 'value1'\")\n",
    "        print(f\"Retrieved records: {records}\")\n",
    "\n",
    "        # UPDATE\n",
    "        updated_rows = db.update(\"your_table\", {\"column2\": \"new_value\"}, \"column1 = 'value1'\")\n",
    "        print(f\"Updated rows: {updated_rows}\")\n",
    "\n",
    "        # DELETE\n",
    "        deleted_rows = db.delete(\"your_table\", \"column1 = 'value1'\")\n",
    "        print(f\"Deleted rows: {deleted_rows}\")\n",
    "\n",
    "    finally:\n",
    "        # Close the connection\n",
    "        db.close_connection()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_scrapy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
